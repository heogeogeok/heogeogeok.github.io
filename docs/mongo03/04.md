---
layout: default
title: 3.4. Compression
parent: 3. Block Manager
nav_order: 4
---

### 3.4. COMPRESSION
{: .fs-10 .text-center }


{: .note }
I/O is the main bottleneck if the DBMS fetches data from disk during query execution.<br>
The DBMS can compress pages to increase the utility of the data moved per I/O operation.<br>


**Goal #1**: Must produce fixed-length values.

→ Only exception is var-length data stored in separate pool.

**Goal #2**: Postpone decompression for as long as possible during query execution.

→ Also known as late materialization.

**Goal #3**: Must be a lossless scheme.

WiredTiger supports compression of your data on disk. There are three places within your data storage that WiredTiger can compress your data and there are two compression algorithms you can use with your data that have slightly different trade-offs:
-  The first and default compression algorithm is the `snappy` compression algorithm.
This compression algorithm provides good compression and has really low overhead
in terms of CPU usage.
-  The second algorithm is the `zlib` compression algorithm. This algorithm provides
very high compression but costs significantly more in terms of CPU and time.
- The third and final compression available within MongoDB is the `none` compression
algorithm, which simply disables compression.

Now that we have covered the compression algorithms, we can look at which MongoDB data you
can compress:
-  Data in your collections.
- Index data, which are the data in your indexes.
- Journal data, which is that used to ensure your data are redundant and recoverable
while they are being written into your long-term data storage.


Finally, armed with a sense of understanding of what compression can be used on which data, let’s look
at how you can compress things. It’s important to note that these options are set in your MongoDB configs when you boot up your instance and will affect only new data objects when created. Any existing objects will continue to use the compression they were created with. For example, if you create a collection with the default `snappy` compression algorithm and then decide you wish to use the `zlib` compression algorithm for your collections, your existing collections will not switch to `snappy` but any new collections will be made with `zlib`. The setting of compression algorithms is done with three different YAML configuration settings that take either `snappy`, `zlib`, or none as the values:
- For **Journal** compression you use the `storage.wiredTiger.engineConfig.
journalCompressor` YAML configuration option, which takes a value of the name of
the compression lib you wish to use.
- For **Index** compression you use the `storage.wiredTiger.indexConfig.
prefixCompression` YAML configuration option, which takes a true or false value to
say if index prefix compression should be on or off. This is on by default.
- For **Collection** compression you use the `storage.wiredTiger.collectionConfig.
blockCompressor` YAML configuration option, which takes a value of the name of the
compression lib you wish to use.

With these options you should be able to configure the compression in your system to best suit your needs.

The WiredTiger storage engine manages data in page units. The pages are connected via a B-tree structure and within each page, data is stored in a cell struct format. Additionally, to reduce data storage space, the Snappy compression algorithm is used to compress the page. The Snappy compression algorithm is used by default, but the settings can be changed.

To search for a page in the WiredTiger storage engine metadata files, WiredTiger.tutle, WiredTiger.wt, and _md_catalog.wt must be interpreted. The WiredTiger.tutle file has a general text file format, and the WiredTiger.wt file's root page offset is included in the configuration string. By interpreting the B-tree structure starting with the WiredTiger.wt file's root page offset and then extracting the data, the configuration strings of the collection-#-####∼.wt file and the _md_catalog.wt file can be determined. The collection-#-####∼.wt file is the file where the actual data is stored. The _md_catalog.wt file stores data that can connect the namespace string and the data file name. The collection-#-####∼.wt file is the file that stores actual user data; one is created per collection. The # in the file name depicts the number, and the number behind the first hyphen increases by one as the files get created. The numbers behind the second hyphen are 19 randomly generated numbers that define the file name. User data is stored in a BSON format in the cell struct of the leaf page.